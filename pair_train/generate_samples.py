# Code to generate chimera augmentations using a trained network.
import torch
import nn as pairnn
import json
import itertools as it
import cPickle
import logging

_formatstr = '%(asctime)s %(name)s %(levelname)s]: %(message)s'

# Set up the logger.
_MYLOGGER = None
def _setupLogger():
  global _MYLOGGER
  LOGLEVEL = logging.DEBUG
  _MYLOGGER = logging.getLogger(__name__)
  ch = logging.StreamHandler()
  ch.setLevel(LOGLEVEL)
  _FORMATTER = logging.Formatter(fmt=_formatstr)
  ch.setFormatter(_FORMATTER)
  _MYLOGGER.addHandler(ch)
  _MYLOGGER.setLevel(LOGLEVEL)
  _MYLOGGER.propagate = False

_setupLogger()

def getLogger():
  global _MYLOGGER
  return _MYLOGGER

class AugmentedDataSet(object):
  EXTENSION = ".ads"
  def __init__(self):
    self._data = []
  def addPoint(self, dataPoint, outputPoint):
    """
    dataPoint: a tuple (x,y), of points and expected outputs 
               ('y' is needed for similarity score)
    outputPoint: the features for this datapoint generated by the network
    """
    self._data.append((dataPoint, outputPoint))
  def addAds(self, ads):
    self._data += ads._data
  @property
  def data(self):
    return self._data
  def sanitize(self, fileName):
    if not fileName.endswith(self.EXTENSION):
      fileName += self.EXTENSION
    return fileName
  def save(self, outFileName):
    outFileName = self.sanitize(outFileName)
    torch.save(self._data, outFileName)
  def saveJson(self, out_filename):
    out_filename = self.sanitize(out_filename) + ".json"
    json.dump(self._data, open(out_filename, "w"))
  def load(self, inFileName):
    inFileName = self.sanitize(inFileName)
    self._data = torch.load(inFileName)

def generate_augmented_chimeras(
    modelFileName, pairFileName, sourceWhitelistName, featDir, gpu_id):
  """
  modelFileName - name of the neural network model file.
  pairFileName - name of the file with vrn pairings.
  sourceWhitelistName - name of a file containing a list of image names. Only
                        pairs in which the first image matches one of these
                        names will be accepted.
  """
  logger = getLogger()
  logger.debug("modelFileName=%s" % modelFileName)
  logger.debug("pairFileName=%s" % pairFileName)
  model = torch.load(modelFileName)
  vrnData = json.load(open(pairFileName))
  whitelists = set(json.load(open(sourceWhitelistName)))
  print "Making data set"
  print "length of whitelists: %d" % len(whitelists)
  dataSet = pairnn.makeDataSet("%s_model_" % modelFileName, featDir, vrnData, whitelists)
  print "Computing features"
  features = pairnn.computeAllFeatures(model, dataSet, gpu_id)

  ret = AugmentedDataSet()

  for i, (dataPoint, outputPoint) in enumerate(it.izip(dataSet, features)):
    if i % 10000 == 9999:
      print "iteration %d of %d" % (i + 1, len(dataSet))
    #print "dataPoint=%s" % str(dataPoint)
    #print "outputPoint=%s" % str(outputPoint)
    ret.addPoint(dataPoint, outputPoint)
  print "Done generating augmented chimeras!"
  return ret

def write_augmented_chimeras(outFileName, *args, **kwargs):
  chimeras = generate_augmented_chimeras(*args, **kwargs)
  print "saving chimeras to %s" % str(outFileName)
  chimeras.save(outFileName)

def chimera_stub():
  # Only runs chimera generation, assumes other files are present.
  outFileName = "data/chimeras.pik"
  modelFileName = "data/models/nn.pyt"
  pairFileName = pairnn.VRNDATA
  sourceWhitelistName = "%s_%s" % (pairnn.TORCHCOMPDEVDATA, "devImgNames.json")
  featDir = pairnn.COMPFEATDIR

  write_augmented_chimeras(outFileName, modelFileName, pairFileName, sourceWhitelistName, featDir)

def generateDepsAndChimeras():
  # One method to run to train the network and generate chimeras.
  # This requires that the relevant pairnn.COMPFEATDIR and pairnn.VRNDATA
  # already exist.

  # Set up variables
  logger = getLogger()
  modelType = "nn"
  modelFileName = "data/models/%s.pyt" % modelType
  featDir = pairnn.COMPFEATDIR
  pairFileName = pairnn.VRNDATA
  trainLoc = pairnn.TORCHCOMPTRAINDATA
  devLoc = pairnn.TORCHCOMPDEVDATA
  # This file contains the image names used as the source in chimera generation
  sourceWhitelistName = "%s_%s" % (devLoc, "devImgNames.json")  

  # Generate everything dont always regenerate
#  pairnn.makeData(trainLoc, devLoc, featDir, pairFileName)
  logger.info("Running model {0}".format(modelType))
  pairnn.runModel(modelFileName, modelType, trainLoc=trainLoc, devLoc=devLoc)
  logger.info("Writing Chimeras")
  logger.debug("modelFileName=%s" % modelFileName)
  logger.debug("pairFileName=%s" % pairFileName)
  write_augmented_chimeras("%s_chimeras" % modelFileName, modelFileName, pairFileName, sourceWhitelistName, featDir)

#if __name__ == '__main__':
#  generateDepsAndChimeras()
